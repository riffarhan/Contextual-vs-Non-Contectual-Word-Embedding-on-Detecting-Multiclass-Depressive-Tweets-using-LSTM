# Contextual vs Non-contextual Word Embedding on Detecting Multiclass Depressive Tweets using Long Short-Term Memory (LSTM)

## Overview
In order to detect tweets on Twitter's social media platform with depressive tones, this study compares contextual and non-contextual word embedding Word2Vec, FastText, and BERT using the LSTM model. According to testing and comparison results, the BERT contextual word embedding model and Long Short-Term Memory worked together to classify depressive tweets more accurately, with an F1-Score score of 95.2% for multiclass datasets.

## Dataset
The dataset used is a combination of datasets published by Yang (2020), Romero (2019), and also Yadav (2018).

## Library Used
- gensim - *enables storing and querying word vectors*
- keras - *a high-level neural networks API running on top of TensorFlow*
- matplotlib - *a Python 2D plotting library which produces publication quality figures*
- numpy - *the fundamental package for scientific computing with Python*
- pandas - *provides easy-to-use data structures and data analysis tools for Python*
- sklearn - *a software machine learning library*
- tensorflow - *an open source machine learning framework for everyone*


```bash
$ jupyter notebook
```



